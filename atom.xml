<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Y-HKL&#39;Blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://y-hkl.top/"/>
  <updated>2017-09-01T06:51:44.324Z</updated>
  <id>http://y-hkl.top/</id>
  
  <author>
    <name>Y-HKL</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>爬取百度搜索</title>
    <link href="http://y-hkl.top/2017/09/01/%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E6%90%9C%E7%B4%A2/"/>
    <id>http://y-hkl.top/2017/09/01/爬取百度搜索/</id>
    <published>2017-09-01T06:31:09.000Z</published>
    <updated>2017-09-01T06:51:44.324Z</updated>
    
    <content type="html"><![CDATA[<p>在用谷歌语法搜索有某些特征的链接时，如果想把这些链接全部保存起来，这个时候就可以使用爬虫技术，爬取这些链接保存下来。下面就来分析并写出这个爬虫程序。<br><a id="more"></a></p>
<h2 id="网页分析"><a href="#网页分析" class="headerlink" title="网页分析"></a>网页分析</h2><h3 id="分析搜索链接"><a href="#分析搜索链接" class="headerlink" title="分析搜索链接"></a>分析搜索链接</h3><p>每页的网页链接格式，一般都有固定的链接格式，如百度的每页搜索结果链接是只取两个个参数的结果是这样，每页10条<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">https://www.baidu.com/s?wd=ctf&amp;pn=10</div></pre></td></tr></table></figure></p>
<h3 id="分析搜索页面中的链接"><a href="#分析搜索页面中的链接" class="headerlink" title="分析搜索页面中的链接"></a>分析搜索页面中的链接</h3><p>F12对当前页面分析每个链接的特点，百度搜索有点坑，你会发现百度都是通过一个长长的链接302跳转来访问的，随便选取一个链接都是这种<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">a target=&quot;_blank&quot; href=&quot;你搜索的URL&quot; class=&quot;c-showurl&quot; style=&quot;text-decoration:none;&quot;&gt;www.php.net/downloa...php</div></pre></td></tr></table></figure></p>
<p>特征就是class=”c-showurl” 属性值，用bs库去获取所有有这个属性的tagres = soup.find_all(name=”a”, attrs={‘class’:’c-showurl’})</p>
<h3 id="访问链接"><a href="#访问链接" class="headerlink" title="访问链接"></a>访问链接</h3><p>访问跳转链接获取实际网站url,title之类的信息</p>
<h2 id="爬虫实现"><a href="#爬虫实现" class="headerlink" title="爬虫实现"></a>爬虫实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment">#coding=utf-8</span></div><div class="line"></div><div class="line"><span class="comment">#输入格式  python 脚本 -s 内容 -f 要保存的文件名</span></div><div class="line"></div><div class="line"><span class="comment">#每页的网页链接格式，一般都有固定的链接格式，如百度的每页搜索结果链接是只取两个个参数的结果是这样，每页10条</span></div><div class="line"><span class="comment">#https://www.baidu.com/s?wd=ctf&amp;pn=10</span></div><div class="line"><span class="comment">#F12对当前页面分析每个链接的特点，百度搜索有点坑，你会发现百度都是通过一个长长的链接302跳转来访问的，随便选取一个链接都是这种</span></div><div class="line"><span class="comment">#&lt;a target="_blank" href="http://www.baidu.com/link?url=GI9K125i3rnLbxL2-kKs-2g2OZt-oDTJZZIFjndQHxGiDubfIEpvNxnnCc1h5ags" class="c-showurl" style="text-decoration:none;"&gt;www.secbox.cn/tag/&lt;b&gt;ctf&lt;/b&gt;&amp;nbsp;&lt;/a&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> requests	</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="keyword">as</span> bs</div><div class="line"><span class="keyword">import</span> threading	<span class="comment">#多线程</span></div><div class="line"><span class="keyword">import</span> re  <span class="comment">#正则</span></div><div class="line"><span class="keyword">from</span> Queue <span class="keyword">import</span> Queue  <span class="comment">#线程优先级队列（ Queue）</span></div><div class="line"><span class="keyword">from</span> prettytable <span class="keyword">import</span> PrettyTable  <span class="comment">#将输出内容如表格方式整齐 </span></div><div class="line"><span class="keyword">import</span> argparse  <span class="comment">#命令行解析</span></div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line">thread_count = <span class="number">3</span> <span class="comment">#进程数</span></div><div class="line">page = <span class="number">5</span> <span class="comment">#可以修改抓取页数</span></div><div class="line">urls = []</div><div class="line"></div><div class="line">table =  PrettyTable([<span class="string">'page'</span>,<span class="string">'url'</span>,<span class="string">'title'</span>]) <span class="comment">#prettyx模块将输出内容如表格方式整齐</span></div><div class="line">table.align[<span class="string">'title'</span>] = <span class="string">'1'</span> <span class="comment">#title左对齐</span></div><div class="line">table.padding_width = <span class="number">1</span>  <span class="comment">#列边和内容之间的一个空格</span></div><div class="line"></div><div class="line">page = (page+<span class="number">1</span>) * <span class="number">10</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">mythread</span><span class="params">(threading.Thread)</span>:</span>  <span class="comment">#继承父类threading.Thread</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,queue)</span>:</span></div><div class="line">		threading.Thread.__init__(self)</div><div class="line">		self.Q = queue</div><div class="line">		self.headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'</span>&#125;  <span class="comment">#设置请求头</span></div><div class="line"></div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span>   <span class="comment">##把要执行的代码写到run函数里面 线程在创建后会直接运行run函数 </span></div><div class="line">		<span class="keyword">while</span> <span class="number">1</span>:</div><div class="line">			<span class="keyword">try</span>:</div><div class="line">				t = self.Q.get(<span class="keyword">True</span>,<span class="number">1</span>)</div><div class="line">				<span class="comment">#print t</span></div><div class="line">				self.spider(t)</div><div class="line">			<span class="keyword">except</span> Exception,e:  <span class="comment">#调试最好打印出错信息，否则，spider函数出错也无法定位错误，多次遇到这个问题了,靠打印才解决</span></div><div class="line">				<span class="keyword">print</span> e</div><div class="line">				<span class="keyword">break</span></div><div class="line"></div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">spider</span><span class="params">(self,target)</span>:</span>  <span class="comment">#爬取网页链接和标题</span></div><div class="line">		<span class="comment">#print type(target)</span></div><div class="line">		pn =int(target.split(<span class="string">'='</span>)[<span class="number">-1</span>])/<span class="number">10</span> + <span class="number">1</span>  <span class="comment">#对https://www.baidu.com/s?wd=ctf&amp;pn=10分割去最后的数字</span></div><div class="line">		<span class="comment">#print pn</span></div><div class="line">		<span class="comment">#print target</span></div><div class="line">		html = requests.get(target,headers=self.headers)</div><div class="line">		<span class="comment">#print html</span></div><div class="line">		soup = bs(html.text,<span class="string">'lxml'</span>)</div><div class="line">		res = soup.find_all(name=<span class="string">'a'</span>, attrs=&#123;<span class="string">'class'</span>:<span class="string">'c-showurl'</span>&#125;)</div><div class="line">		<span class="comment">#print res</span></div><div class="line">	</div><div class="line">		<span class="keyword">for</span> r <span class="keyword">in</span> res:</div><div class="line">			<span class="keyword">try</span>:</div><div class="line">				<span class="comment">#因为百度搜索是302跳转，所以我们需要再次请求</span></div><div class="line">				h = requests.get(r[<span class="string">'href'</span>],headers=self.headers,timeout=<span class="number">3</span>)</div><div class="line">				<span class="keyword">if</span> h.status_code == <span class="number">200</span>:</div><div class="line">					url = h.url</div><div class="line">					title =re.findall(<span class="string">r'&lt;title&gt;(.*?)&lt;/title&gt;'</span>,h.content)[<span class="number">0</span>]</div><div class="line">					title = title.decode(<span class="string">'utf-8'</span>)  <span class="comment">#解码成unicode,否则add_row会转换出错</span></div><div class="line">					urls.append((pn,url,title))</div><div class="line">				<span class="keyword">else</span>:</div><div class="line">					<span class="keyword">continue</span></div><div class="line">			<span class="keyword">except</span>:</div><div class="line">				<span class="keyword">continue</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">Load_Thread</span><span class="params">(queue)</span>:</span>   <span class="comment">#生成线程数</span></div><div class="line">	<span class="keyword">return</span> [mythread(queue) <span class="keyword">for</span> i <span class="keyword">in</span> range(thread_count)]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">Start_Thread</span><span class="params">(threads)</span>:</span></div><div class="line">	<span class="keyword">print</span> <span class="string">'thread is start...'</span></div><div class="line">	<span class="keyword">for</span> t <span class="keyword">in</span> threads:</div><div class="line">		t.setDaemon(<span class="keyword">True</span>)</div><div class="line">		t.start()</div><div class="line">	<span class="keyword">for</span> t <span class="keyword">in</span> threads:</div><div class="line">		t.join()</div><div class="line">	<span class="keyword">print</span> <span class="string">'thread is end...'</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">	start = time.time()</div><div class="line">	parser = argparse.ArgumentParser()</div><div class="line">	parser.add_argument(<span class="string">'-s'</span>)</div><div class="line">	parser.add_argument(<span class="string">'-f'</span>)</div><div class="line">	arg = parser.parse_args()</div><div class="line">	<span class="comment">#print arg</span></div><div class="line">	</div><div class="line">	word = arg.s</div><div class="line">	output = arg.f</div><div class="line">	<span class="comment"># word = 'inurl:login.action'</span></div><div class="line">	<span class="comment"># output = 'test.txt'</span></div><div class="line">	queue = Queue()</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,page,<span class="number">10</span>):</div><div class="line">		target = <span class="string">'https://www.baidu.com/s?wd=%s&amp;pn=%s'</span>%(word,i)</div><div class="line">		queue.put(target)</div><div class="line">	thread_list = Load_Thread(queue)</div><div class="line">	Start_Thread(thread_list)</div><div class="line">	</div><div class="line">	<span class="comment">#把数据写到文件中</span></div><div class="line">	<span class="keyword">if</span> output:</div><div class="line">		<span class="keyword">with</span> open(output,<span class="string">'a'</span>) <span class="keyword">as</span> f:</div><div class="line">			<span class="keyword">for</span> record <span class="keyword">in</span> urls:</div><div class="line">				f.write(record[<span class="number">1</span>]+<span class="string">'\n'</span>)</div><div class="line">	<span class="comment">#print urls,len(urls)</span></div><div class="line">	<span class="keyword">for</span> record <span class="keyword">in</span> urls:</div><div class="line">		table.add_row(list(record))  <span class="comment">#在表单中添加数据</span></div><div class="line">	<span class="keyword">print</span> table</div><div class="line">	<span class="keyword">print</span> <span class="string">'共爬取数据%s条'</span>%len(urls)</div><div class="line">	<span class="keyword">print</span> time.time()-start</div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">	main()</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在用谷歌语法搜索有某些特征的链接时，如果想把这些链接全部保存起来，这个时候就可以使用爬虫技术，爬取这些链接保存下来。下面就来分析并写出这个爬虫程序。&lt;br&gt;
    
    </summary>
    
      <category term="爬虫技术" scheme="http://y-hkl.top/categories/%E7%88%AC%E8%99%AB%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="python爬虫" scheme="http://y-hkl.top/tags/python%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>web常见漏洞脑图</title>
    <link href="http://y-hkl.top/2017/08/31/web%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E8%84%91%E5%9B%BE/"/>
    <id>http://y-hkl.top/2017/08/31/web常见漏洞脑图/</id>
    <published>2017-09-01T03:00:44.000Z</published>
    <updated>2017-09-01T03:36:48.140Z</updated>
    
    <content type="html"><![CDATA[<h2 id="web常见漏洞脑图"><a href="#web常见漏洞脑图" class="headerlink" title="web常见漏洞脑图"></a>web常见漏洞脑图</h2><p><img src="/upload_img/web_mind_map.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;web常见漏洞脑图&quot;&gt;&lt;a href=&quot;#web常见漏洞脑图&quot; class=&quot;headerlink&quot; title=&quot;web常见漏洞脑图&quot;&gt;&lt;/a&gt;web常见漏洞脑图&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/upload_img/web_mind_map.png&quot; al
    
    </summary>
    
      <category term="web安全" scheme="http://y-hkl.top/categories/web%E5%AE%89%E5%85%A8/"/>
    
    
      <category term="脑图" scheme="http://y-hkl.top/tags/%E8%84%91%E5%9B%BE/"/>
    
      <category term="漏洞" scheme="http://y-hkl.top/tags/%E6%BC%8F%E6%B4%9E/"/>
    
  </entry>
  
</feed>
